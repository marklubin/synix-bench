"""Letta (formerly MemGPT) memory adapter for LENS.

Uses Letta's archival memory (semantic vector search) as the memory backend.
One Letta agent per scope — the agent is the isolation/namespace unit.
"""
from __future__ import annotations

import os
import re

from synix.suites.lens.adapters.base import (
    CapabilityManifest,
    Document,
    ExtraTool,
    MemoryAdapter,
    SearchResult,
)
from synix.suites.lens.adapters.registry import register_adapter
from synix.core.errors import AdapterError

_EP_ID_RE = re.compile(r"^\[([^\]]+)\]")

_PERSONA = (
    "I am an archival memory store for the LENS benchmark. "
    "My role is to accurately store and retrieve sequential episode logs "
    "for longitudinal analysis. I do not editorialize or add context."
)

_DEFAULT_LLM = "together/Qwen/Qwen3-235B-A22B-Instruct-2507-tput"
_DEFAULT_EMBED = "together-oai/text-embedding-3-small"


def _parse_ep_id(content: str) -> str:
    """Extract episode_id from '[ep_id] text' content format."""
    m = _EP_ID_RE.match(content)
    return m.group(1) if m else content[:32]


@register_adapter("letta")
class LettaAdapter(MemoryAdapter):
    """Letta archival memory adapter."""

    requires_metering: bool = False

    def __init__(self) -> None:
        self._base_url = os.environ.get("LETTA_BASE_URL", "http://localhost:8283")
        self._llm_model = os.environ.get("LETTA_LLM_MODEL", _DEFAULT_LLM)
        self._embed_model = os.environ.get("LETTA_EMBED_MODEL", _DEFAULT_EMBED)
        self._client = None

        self._agent_id: str | None = None
        self._scope_id: str | None = None
        self._text_cache: dict[str, str] = {}

    def _get_client(self):
        if self._client is None:
            try:
                from letta_client import Letta  # noqa: PLC0415
            except ImportError as e:
                raise AdapterError(
                    "letta-client not installed. Run: pip install letta-client"
                ) from e
            self._client = Letta(base_url=self._base_url, api_key="dummy")
        return self._client

    def reset(self, scope_id: str) -> None:
        client = self._get_client()

        if self._agent_id is not None:
            try:
                client.agents.delete(agent_id=self._agent_id)
            except Exception:
                pass

        try:
            for agent in client.agents.list():
                if agent.name == f"lens-{scope_id}":
                    try:
                        client.agents.delete(agent_id=agent.id)
                    except Exception:
                        pass
        except Exception:
            pass

        try:
            agent = client.agents.create(
                name=f"lens-{scope_id}",
                model=self._llm_model,
                embedding=self._embed_model,
                memory_blocks=[
                    {
                        "label": "human",
                        "value": f"LENS benchmark scope: {scope_id}",
                    },
                    {
                        "label": "persona",
                        "value": _PERSONA,
                    },
                ],
            )
        except Exception as e:
            raise AdapterError(
                f"Failed to create Letta agent. Is the server running at "
                f"{self._base_url}? Error: {e}"
            ) from e

        self._agent_id = agent.id
        self._scope_id = scope_id
        self._text_cache = {}

    def ingest(
        self,
        episode_id: str,
        scope_id: str,
        timestamp: str,
        text: str,
        meta: dict | None = None,
    ) -> None:
        if not self._agent_id:
            raise AdapterError("reset() must be called before ingest()")

        content = f"[{episode_id}] {timestamp}: {text}"

        client = self._get_client()
        client.agents.passages.create(
            agent_id=self._agent_id,
            text=content,
        )

        self._text_cache[episode_id] = text

    def search(
        self,
        query: str,
        filters: dict | None = None,
        limit: int | None = None,
    ) -> list[SearchResult]:
        if not query or not query.strip():
            return []
        if not self._agent_id:
            return []

        limit = limit or 10
        client = self._get_client()

        try:
            response = client.agents.passages.search(
                agent_id=self._agent_id,
                query=query,
            )
        except Exception:
            return []

        raw = getattr(response, "results", None)
        if raw is None:
            raw = response if isinstance(response, list) else []

        results = []
        for item in raw[:limit]:
            content = getattr(item, "content", None) or getattr(item, "text", "")
            ep_id = _parse_ep_id(content)
            results.append(SearchResult(
                ref_id=ep_id,
                text=content[:500],
                score=0.0,
                metadata={"timestamp": getattr(item, "timestamp", "")},
            ))

        return results

    def retrieve(self, ref_id: str) -> Document | None:
        text = self._text_cache.get(ref_id)
        if text is None:
            return None
        return Document(ref_id=ref_id, text=text)

    def get_capabilities(self) -> CapabilityManifest:
        return CapabilityManifest(
            search_modes=["semantic"],
            max_results_per_search=10,
            extra_tools=[
                ExtraTool(
                    name="batch_retrieve",
                    description=(
                        "Retrieve multiple full episodes by their reference IDs in a single call. "
                        "PREFER this over calling memory_retrieve multiple times — it uses only "
                        "one tool call instead of one per document. "
                        "After memory_search, pass all ref_ids you want to read to this tool."
                    ),
                    parameters={
                        "type": "object",
                        "properties": {
                            "ref_ids": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "List of reference IDs to retrieve.",
                            },
                        },
                        "required": ["ref_ids"],
                    },
                ),
            ],
        )

    def call_extended_tool(self, tool_name: str, arguments: dict) -> object:
        if tool_name == "batch_retrieve":
            ref_ids = arguments.get("ref_ids", [])
            docs = []
            for ref_id in ref_ids:
                doc = self.retrieve(ref_id)
                if doc is not None:
                    docs.append(doc.to_dict())
            return {"documents": docs, "count": len(docs)}
        return super().call_extended_tool(tool_name, arguments)
